---
title: Multiplier
date: 2025-06-13T10:00:00+1000
lastmod: 2025-06-13T10:00:00+1000
categories:
  - Work
  - AI
---

I've been trying to reconcile the way I feel about AI. (It's been a hot topic on [https://async.fm](Async) recently.)

On the one hand, I see so much shitty code submitted to the WordPress plugin repo. It's easy to see how AI is making things _way_ worse for the web – in terms of security, homogenisation, and long-term maintainability. There are legitimate concerns about loss of craft, content scraping, and [enshittification](https://diggingforfire.blog/posts/trapped-in-an-eternal-cycle-of-enshittification/).

On the other hand, I use AI for help every time I write code! It's a far cry from _vIbE cOdInG_, but it's unlocked possibilities in ways I never thought possible. ChatGPT has, undoubtedly, made me a better developer! Writers like Joshua Wold use AI to line-edit finished pieces, and learn a lot about writing better prose in the process. I even use AI writing this blog for things like "what's that word…?" and rubber ducking.

I've got the ChatGPT shortcut under my fingers, and I often find myself instinctively invoking it. I worry about the long-term effects that might have on my brain, as I reflexively hand off hard thinking. I worry about the long-term effects that might have on all our brains.

My current mental model is that AI is a sliding scale multiplier. The slider shifts based on the operator's effort.

```
              Operator Effort
<------ low  ------ mid  ------ high ------>
<------ 0.5x ------ 0.9x ------ 3.0x ------>
                 AI Impact
```

AI **will** impact the quality of our work, our working knowledge, and our skill. If I allow AI to complete tasks without any struggle or oversight, the result will be worse, and over time, my skill will degrade.

But if I employ AI as a true "copilot" – an assistant who can step in to help when I really need it – I unlock opportunities to improve, and to try new things I wouldn't otherwise have the confidence to attempt.

Teachers talk endlessly about "Digital Literacy" and "21st Century" competencies. That was important 20 years ago, but is no longer relevant. Today's school students have been "native digital citizens" since before their fifth birthday. It's time for a change. We're in dire need of understanding how AI influences thinking and learning, so that we can embed AI Literacy in our curricula.
